{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PRSM</h2>\n",
    "\n",
    "<b>P</b>CA with <b>R</b>andom Matrix Theoretic <b>S</b>pectral <b>M</b>easures\n",
    "\n",
    "PRSM is a python package applying Random Matrix Theory (RMT) to high-dimensional PCA. PRSM fits densities to the empirical eigenvalue distribution with the goal of estimating various quantities associated with outlying eigenvalues. This includes diagnostic quantities which may be used to test whether or not a candidate eigenvalue is an outlier, or whether neighboring outlying eigenvalues are too close to trust estimates of the overlap between sample and population eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Brief random matrix theory overview</h3>\n",
    "\n",
    "The main model of random matrix theory applications to high-dimensional data is as follows.  We consider an $N \\times M$ data matrix $X$ of $N$ independent samples of $M$-dimensional data.  If the spectral measure of the population covariance matrix $\\Sigma := N^{-1} \\mathbb{E} X X^T$ converges to a measure $H$, then the spectral measure of the sample covariance matrix converges to a deterministic measure $\\rho(x)$ which is a function of $H$ defined below.  The Stieltjes transform of $\\rho$ is defined by,\n",
    "$$\n",
    "m (z) = \\int \\frac{ \\rho (x) }{x -z} d x.\n",
    "$$\n",
    "The matrices $ N^{-1} X X^T$ and $N^{-1} X^T X$ have the same eigenvalues up to $|M-N|$ zeros and so the empirical spectral measure of the latter matrix also converges to a deterministic measure which we denote by $\\tilde{\\rho}$ with Stieltjes transform $\\tilde{m} (z)$ related to $m(z)$ by\n",
    "$$\n",
    "\\gamma z m(z) = (1- \\gamma) + z \\tilde{m} (z)\n",
    "$$\n",
    "where $\\gamma$ is the limit of the ratio $M/N$. The function $\\tilde{m}(z)$ satisfies the functional equation,\n",
    "$$\n",
    "\\tilde{m} (z) = - \\left( z - \\gamma \\int \\frac{ x d H (x) }{  1 + x \\tilde{m} (z) } \\right)^{-1}\n",
    "$$\n",
    "This may also be used to define $\\tilde{m}(z)$ as the holomorphic solution of the above equation satisfying $\\tilde{m}(z) \\sim z^{-1}$ as $|z| \\to \\infty$, which then in turn defines $m(z)$ and the corresponding measures through the Stieltjes inversion formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Theoretical behavior of outliers</h3>\n",
    "\n",
    "Let $\\psi ( \\alpha )$ be the function,\n",
    "$$\n",
    "\\psi ( \\alpha) := \\alpha + \\gamma \\alpha \\int \\frac{ x d H (x ) }{ \\alpha - x }.\n",
    "$$\n",
    "The functional relation \n",
    "$$\n",
    "\\psi ( -1 / \\tilde{m} (z) ) = z\n",
    "$$\n",
    "holds.  Denote by $\\mathfrak{p}$ the point,\n",
    "$$\n",
    "\\mathfrak{p} := \\inf_p \\{ p' :  \\psi' (p' ) > 0 \\mbox{ } \\forall \\mbox{ }p' > p \\}.\n",
    "$$\n",
    "Any population eigenvalue of $\\Sigma$ such that $p > \\mathfrak{p}$ gives rise to an outlying eigenvalue $s$ of the sample covariance matrix. The locations of $s$ and $p$ are related asymptotically by,\n",
    "$$\n",
    "p \\approx - \\frac{1}{ \\tilde{m} (s) }.\n",
    "$$\n",
    "Moreover, if the population eigenvalue $p$ is simple, the squared inner product between sample and population eigenvectors converges to the deterministic quantity\n",
    "$$\n",
    "- \\frac{ s \\tilde{m}(s) }{ \\tilde{m}' (s) }.\n",
    "$$\n",
    "Both the sample eigenvalue and the squared overlap of the sample and population eigenvectors exhibit fluctuations.  When the population eigenvalue is simple, the sample eigenvalue has Gaussian fluctuations.  If the population eigenvector is localized then the variance depends on the fourth cumulant of the matrix entries.  In the event that this cumulant vanishes (e.g., the Gaussian distribution) the variance is known to be,\n",
    "$$\n",
    "\\mathrm{Var} ( s) \\approx \\frac{2}{N \\tilde{m}''(s)}.\n",
    "$$\n",
    "If the population eigenvector is delocalized, then due to universality this expression is expected to hold asymptotically.  Under similar conditions, the variance of the squared overlap between sample and population eigenvectors is,\n",
    "$$\n",
    "\\mathrm{Var} ( (v_s \\cdot v_p)^2 ) \\approx \\frac{1}{3N} \\frac{ \\tilde{m}'''(s) ( \\tilde{m} (s) )^4}{s^2 ( \\tilde{m}' (s) )^4}  \\approx ( v_s \\cdot v_p )^2 \\frac{\\tilde{m}'''(s) \\tilde{m}(s)^2 }{ 3N \\tilde{m}'(s)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practical considerations</h3>\n",
    "In practice, it can be difficult to decide which eigenvalues are truly outliers and which belong to the spectral bulk.  In the case that $H$ is trivial, Johnstone proposed a hypothesis testing framework based on the fact that under the absence of outliers, the limiting distribution of the largest eigenvalue is Tracy-Widom.  The p-value is then  $\\mathbb{P}_{TW}  ( \\lambda > s)$.\n",
    "\n",
    "A goal of PRSM is to build on this approach by reporting further diagnostic quantities and additionally treating the case in which the typical square-root behavior and Tracy-Widom fluctuations are absent.  PRSM aims to estimate the various quantities listed above, including the variances of the sample eigenvalue and the squared overlap.  As seen from the above formulas, all quantities may be related to the limiting density of states $\\rho (x)$.\n",
    "\n",
    "Due to the functional relation between $\\psi$ and $\\tilde{m}$, one can instead try to estimate $H$.  This is the approach proposed by Dey-Lee and El Karoui.  Our approach is different and based on the observations that it is not necessary to estimate $H$; in fact, in the theoretical set-up above there is no reason why one cannot simply estimate the density $\\rho$ by the empirical measure\n",
    "$$\n",
    "\\rho(x) \\approx \\frac{1}{M} \\sum_{i=1}^M \\delta_{ \\lambda_i} (x).\n",
    "$$\n",
    "Indeed, the limit $\\rho$ is somewhat of a theoretical abstraction.  Nonetheless, this approximation has some limitations.  The main limitation is in the fact that the approximation\n",
    "$$\n",
    "m(s) \\approx \\frac{1}{M} \\sum_i \\frac{1}{ \\lambda_i - s}\n",
    "$$\n",
    "breaks down near the spectral edge.  In deed, the limit of the RHS is $\\infty$ as $s$ approaches the edge of the spectrum, while often the LHS has a finite limit as $s$ approaches the edge of the support of $\\rho(x)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> PRSM functionality</h3>\n",
    "PRSM seeks to fit a spectral measure to the empirical eigenvalue measure by fitting a continuous density to a fraction of the eigenvalues near the spectral edge, and just using the empirical measure for the remaining eigenvalues.  A common observation in RMT is that the limiting density of states has a square root behavior, \n",
    "$$\n",
    "\\rho(x) \\approx \\sqrt{E-x}.\n",
    "$$\n",
    "For a given exponent $\\alpha >0$ and cutoff $n$ PRSM approximates the empirical eigenvalue measure as,\n",
    "$$\n",
    "\\frac{1}{M} \\sum_i \\delta_{ \\lambda_i } (x) \\approx c (E-x)^\\alpha \\mathbb{1}_{\\{ \\lambda_n < x < E\\} } + \\frac{1}{M} \\sum_{i >n} \\delta_{ \\lambda_i} (x).\n",
    "$$\n",
    "The exponent $\\alpha >0$ may be chosen by the user (the generic choice in RMT is $\\alpha = 0.5$). PRSM also provides a tool to find $\\alpha$, however this appears to be somewhat sensitive and requires large datasets.  PRSM also allows for higher-order corrections to the continuous density.\n",
    "\n",
    "After finding the approximate spectral measure, PRSM calculates the quantities listed above as well as the distance between the sample eigenvalue and the edge $E$ of the fitted spectral measure.  In the case that $\\alpha = 0.5$, PRSM moreover finds the correct scaling constants for the TW-distribution and reports the mean and variance of a Tracy-Widom random variable under the null hypothesis that $\\Sigma$ contains no outliers.  Our view is that the distance between outlier and spectral edge when normalized by the standard deviation of the sample eigenvalue or TW distribution can serve as meaningful diagnostic tools to alert the user that an eigenvalue may be too close to the spectrum and estimates of the population eigenvalue squared overlap may not be reliable.  \n",
    "\n",
    "In fact it is known (Bloemendal et. al), that when $s-E$ is on the same scale as the $N^{-2/3}$ Tracy-Widom fluctuations, that sample eigenvector no longer has any correlation with the population eigenvector - the goal of PRSM is to essentially fit data to find what this length scale is.\n",
    "\n",
    "An additional diagnostic is the RHS of,\n",
    "$$\n",
    "\\frac{ \\mathrm{Var} ( (v_s \\cdot v_p )^2 )}{ (v_s \\cdot v_p)^2 } \\approx \\frac{\\tilde{m}'''(s) \\tilde{m}(s)^2}{3N \\tilde{m}'(s)^2}.\n",
    "$$\n",
    "As $s$ approaches $E$ this behaves, in the square-root setting, as $(N (s-E)^{3/2} )^{-1}$.  This quantity is large only when $s$ is on the Tracy-Widom scale, and so can serve as another diagnostic.  In any case it is an estimate of the relative error of the squared overlap and if it is large, then the estimate of the squared overlap may not be reliable.  This observation does not depend on the square root behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
